{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "808332b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import ListedColormap\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, make_scorer\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset, random_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn.functional as F\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "449f07d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(xlabel, df, predictions, sonic, v_label, r_label, vrh_label, xlim_lr, xlim_upr, ylim_lr = False, ylim_upr = False, bckg = False):\n",
    "    \"\"\"\n",
    "    Plots various geological log data and machine learning predictions as a function of depth.\n",
    "    \n",
    "    Parameters:\n",
    "    - xlabel (str): Label for the x-axis.\n",
    "    - df (DataFrame): Pandas DataFrame containing the well log data.\n",
    "    - predictions (array-like): Predicted values from a machine learning model.\n",
    "    - sonic (array-like): Sonic log values from the DataFrame.\n",
    "    - v_label (str): Column name in df for Voigt boundary data.\n",
    "    - r_label (str): Column name in df for Reuss boundary data.\n",
    "    - vrh_label (str): Column name in df for Voigt-Reuss-Hill average data.\n",
    "    - xlim_lr (float): Lower limit for the x-axis range.\n",
    "    - xlim_upr (float): Upper limit for the x-axis range.\n",
    "    - ylim_lr (float, optional): Lower limit for the y-axis range. Defaults to False, which auto-scales.\n",
    "    - ylim_upr (float, optional): Upper limit for the y-axis range. Defaults to False, which auto-scales.\n",
    "    - bckg (str or False, optional): Background color for the area between Voigt and Reuss boundaries. If False, yellow is used as the default color.\n",
    "    \n",
    "    The function creates a vertical plot typically used for well log representation with depth increasing downwards. \n",
    "    It plots the sonic log, machine learning predictions, and the Voigt-Reuss-Hill average as lines on the same plot. \n",
    "    It also shades the area between the Voigt and Reuss boundaries to indicate uncertainty or variability range. \n",
    "    The function allows for customization of the x and y-axis limits and the background color for the shaded area.\n",
    "    \"\"\"\n",
    "\n",
    "    depth = df['DEPT']\n",
    "    voigt_boundary = df[v_label]\n",
    "    reuss_boundary = df[r_label]\n",
    "    vp_vrh = df[vrh_label]\n",
    "    xlen = df.shape[0]\n",
    "    \n",
    "    plt.figure(figsize=(9, 10))\n",
    "    plt.gca().invert_yaxis()\n",
    "    plt.gca().xaxis.tick_top()\n",
    "    plt.gca().xaxis.set_label_position('top')\n",
    "    \n",
    "    for _, el in formation_depths.iterrows():\n",
    "        plt.axhline(y=el['Min Value'], color='grey', linestyle='--', linewidth=1, alpha=0.3)\n",
    "        plt.axhline(y=el['Max Value'], color='grey', linestyle='--', linewidth=1, alpha=0.3)\n",
    "        \n",
    "#         if np.isfinite(el['Min Value']) and np.isfinite(el['Max Value']):\n",
    "#               plt.fill_betweenx(y=[el['Min Value'], el['Max Value']], \n",
    "#                                 x1=xlim_lr, x2=xlim_upr,\n",
    "#                                 color=el['color'], alpha=0.1)\n",
    "                \n",
    "    plt.plot(sonic, depth, label='Sonic Log', alpha=1)\n",
    "    plt.plot(predictions, depth, label='ML Predictions', alpha=0.8, color='red')\n",
    "    plt.plot(vp_vrh, depth, label='Voigt Reuss Hill', alpha=0.5, color='black')\n",
    "    plt.plot(voigt_boundary, depth,  alpha=0.8, linewidth=0.4, color='violet')\n",
    "    plt.plot(reuss_boundary, depth, label='Voigt-Reuss Boundaries', alpha=0.8, linewidth=0.4, color='violet')\n",
    "    \n",
    "    if bckg:\n",
    "        plt.fill_betweenx(depth, voigt_boundary, reuss_boundary, where=(voigt_boundary >= reuss_boundary), \n",
    "                      interpolate=True, color=bckg, alpha=0.5)\n",
    "    else:\n",
    "        plt.fill_betweenx(depth, voigt_boundary, reuss_boundary, where=(voigt_boundary >= reuss_boundary), \n",
    "                      interpolate=True, color='yellow', alpha=0.5)\n",
    "    \n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5, -0.05), shadow=True, ncol=2, \n",
    "               framealpha=1.0, edgecolor='black', facecolor='white', frameon=True)\n",
    "    \n",
    "    plt.ylabel('Depth [m]', fontweight='bold', labelpad=15)\n",
    "    plt.xlabel(xlabel, fontweight='bold', labelpad=15)\n",
    "    \n",
    "    plt.rcParams['font.size'] = 20\n",
    "    plt.rcParams['font.family'] = 'arial'\n",
    "    \n",
    "    plt.xlim(xlim_lr, xlim_upr)\n",
    "    if (ylim_lr and ylim_upr):\n",
    "        plt.ylim(ylim_lr, ylim_upr)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccb4dd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_true_vs_predicted(ax, y_true, y_pred, title):\n",
    "    \"\"\"\n",
    "    Plots true vs predicted values with a reference line (y=x).\n",
    "    \n",
    "    Parameters:\n",
    "    - ax: Matplotlib Axes object to plot on.\n",
    "    - y_true: Array-like, true target values.\n",
    "    - y_pred: Array-like, predicted values.\n",
    "    - title: String, title of the plot.\n",
    "    \"\"\"\n",
    "    ax.scatter(y_true, y_pred, alpha=0.5)\n",
    "    ax.plot([y_true.min(), y_true.max()], [y_true.min(), y_true.max()], 'k--', lw=4)\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel('True Values')\n",
    "    ax.set_ylabel('Predictions')\n",
    "\n",
    "def plot_true_vs_predicted_v1(ax, true_data, predicted_data, label, marker, color):\n",
    "    \"\"\"\n",
    "    Enhanced true vs predicted plot with custom styling and legend.\n",
    "    \n",
    "    Parameters:\n",
    "    - ax: Matplotlib Axes object.\n",
    "    - true_data: Array-like, true values.\n",
    "    - predicted_data: Array-like, predicted values.\n",
    "    - label: String, legend label.\n",
    "    - marker: String, marker style.\n",
    "    - color: String, color of the plot points.\n",
    "    \"\"\"\n",
    "    ax.scatter(true_data, predicted_data, alpha=0.7, label=label, marker=marker, color=color)\n",
    "    ax.plot([true_data.min(), true_data.max()], [true_data.min(), true_data.max()], 'k--', alpha=0.5)\n",
    "    ax.set_xlabel('True Values', fontweight='bold')\n",
    "    ax.set_ylabel('Predicted Values', fontweight='bold')\n",
    "    ax.set_title('True vs Predicted', fontweight='bold')\n",
    "    ax.legend()\n",
    "\n",
    "def plot_true_vs_predicted_v2(ax, true_data, predicted_data, label, marker, color, x_pos, y_pos):\n",
    "    \"\"\"\n",
    "    True vs predicted plot with MAE and R² metrics displayed.\n",
    "    \n",
    "    Parameters:\n",
    "    - ax: Matplotlib Axes object.\n",
    "    - true_data: Array-like, true values.\n",
    "    - predicted_data: Array-like, predicted values.\n",
    "    - label: String, legend label.\n",
    "    - marker: String, marker style.\n",
    "    - color: String, color of the plot points.\n",
    "    - x_pos, y_pos: Floats, position of metrics text on the plot (relative axes coordinates).\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(true_data, predicted_data)\n",
    "    r2 = r2_score(true_data, predicted_data)\n",
    "    ax.scatter(true_data, predicted_data, alpha=0.5, label=f'{label}', color=color, marker=marker)\n",
    "    ax.plot([true_data.min(), true_data.max()], [true_data.min(), true_data.max()], 'k--', alpha=0.5)\n",
    "    ax.set_xlabel('True Values', fontweight='bold')\n",
    "    ax.set_ylabel('Predicted Values', fontweight='bold')\n",
    "    ax.set_title('True vs Predicted', fontweight='bold')\n",
    "    ax.text(x_pos, y_pos, f'{label} Metrics:\\nMAE: {mae:.2f}\\nR²: {r2:.2f}', \n",
    "            transform=ax.transAxes, verticalalignment='top', horizontalalignment='left', fontsize=10, \n",
    "            bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=color, facecolor='white'))\n",
    "\n",
    "def plot_true_vs_vrh(ax, true_data, predicted_data, label, marker, color, x_pos, y_pos):\n",
    "    \"\"\"\n",
    "    True vs VRH values plot with MAE and R² metrics displayed.\n",
    "    \n",
    "    Parameters:\n",
    "    - ax: Matplotlib Axes object.\n",
    "    - true_data: Array-like, true values.\n",
    "    - predicted_data: Array-like, VRH values.\n",
    "    - label: String, legend label.\n",
    "    - marker: String, marker style.\n",
    "    - color: String, color of the plot points.\n",
    "    - x_pos, y_pos: Floats, position of metrics text on the plot (relative axes coordinates).\n",
    "    \"\"\"\n",
    "    mae = mean_absolute_error(true_data, predicted_data)\n",
    "    r2 = r2_score(true_data, predicted_data)\n",
    "    ax.scatter(true_data, predicted_data, alpha=0.4, label=f'{label}', color=color, marker=marker)\n",
    "    ax.plot([true_data.min(), true_data.max()], [true_data.min(), true_data.max()], 'k--', alpha=0.5)\n",
    "    ax.set_xlabel('True Values', fontweight='bold')\n",
    "    ax.set_ylabel('VRH Values', fontweight='bold')\n",
    "    ax.set_title('True vs VRH', fontweight='bold')\n",
    "    plt.xlim(2000, 7000)\n",
    "    ax.text(x_pos, y_pos, f'{label} Metrics:\\nMAE: {mae:.2f}\\nR²: {r2:.2f}', \n",
    "            transform=ax.transAxes, verticalalignment='top', horizontalalignment='left', \n",
    "            fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=color, facecolor='white'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80e4210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_voigt_reuss_bounds(df, minerals, bulk_modulus, shear_modulus):\n",
    "    \"\"\"\n",
    "    Calculates the Voigt and Reuss bounds for bulk and shear moduli based on mineralogical composition.\n",
    "\n",
    "    This function computes the Voigt and Reuss bounds for bulk and shear moduli \n",
    "    for a given dataset of mineral volume fractions. It also calculates the average \n",
    "    moduli (Voigt-Reuss-Hill averages) and adds the results as new columns to the input DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    df (pandas.DataFrame): \n",
    "        A DataFrame containing the volume fractions of minerals for each sample.\n",
    "    minerals (list): \n",
    "        A list of column names representing the minerals in the DataFrame.\n",
    "    bulk_modulus (dict): \n",
    "        A dictionary mapping each mineral to its bulk modulus (GPa).\n",
    "    shear_modulus (dict): \n",
    "        A dictionary mapping each mineral to its shear modulus (GPa).\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    pandas.DataFrame:\n",
    "        The input DataFrame with the following additional columns:\n",
    "        - `Voigt_Bulk`: Voigt bound for bulk modulus.\n",
    "        - `Reuss_Bulk`: Reuss bound for bulk modulus.\n",
    "        - `Voigt_Shear`: Voigt bound for shear modulus.\n",
    "        - `Reuss_Shear`: Reuss bound for shear modulus.\n",
    "        - `K_VRH`: Average bulk modulus (Voigt-Reuss-Hill average).\n",
    "        - `G_VRH`: Average shear modulus (Voigt-Reuss-Hill average).\n",
    "\n",
    "    Calculation Details:\n",
    "    --------------------\n",
    "    - Voigt Bound: Assumes a uniform strain distribution and is calculated as the weighted sum \n",
    "      of the mineral moduli (bulk or shear) using their volume fractions.\n",
    "    - Reuss Bound: Assumes a uniform stress distribution and is calculated as the reciprocal of \n",
    "      the weighted sum of the reciprocal mineral moduli (bulk or shear) using their volume fractions.\n",
    "    - Voigt-Reuss-Hill Average (VRH): The average of the Voigt and Reuss bounds.\n",
    "\n",
    "    Example:\n",
    "    --------\n",
    "    Given the following input:\n",
    "    - `df` with columns `Mineral1`, `Mineral2`, ... containing volume fractions.\n",
    "    - `bulk_modulus = {'Mineral1': 40, 'Mineral2': 60}`.\n",
    "    - `shear_modulus = {'Mineral1': 20, 'Mineral2': 30}`.\n",
    "\n",
    "    The function computes the Voigt, Reuss, and VRH averages for each row in the DataFrame.\n",
    "\n",
    "    Usage:\n",
    "    ------\n",
    "    df = calculate_voigt_reuss_bounds(df, minerals, bulk_modulus, shear_modulus)\n",
    "    \"\"\"\n",
    "    dataset = df[minerals]\n",
    "    voigt_bulk = []\n",
    "    reuss_bulk = []\n",
    "    voigt_shear = []\n",
    "    reuss_shear = []\n",
    "    \n",
    "    for index, row in dataset.iterrows():\n",
    "        sum_voigt_bulk = sum_voigt_shear = 0\n",
    "        sum_reuss_bulk = sum_reuss_shear = 0\n",
    "        for mineral in minerals:\n",
    "            volume_fraction = row[mineral]\n",
    "            sum_voigt_bulk += volume_fraction * bulk_modulus[mineral]\n",
    "            sum_voigt_shear += volume_fraction * shear_modulus[mineral]\n",
    "            # Avoid division by zero\n",
    "            if bulk_modulus[mineral] > 0:\n",
    "                sum_reuss_bulk += volume_fraction / bulk_modulus[mineral]\n",
    "            if shear_modulus[mineral] > 0:\n",
    "                sum_reuss_shear += volume_fraction / shear_modulus[mineral]\n",
    "        voigt_bulk.append(sum_voigt_bulk)\n",
    "        voigt_shear.append(sum_voigt_shear)\n",
    "        reuss_bulk_value = 1 / sum_reuss_bulk if sum_reuss_bulk > 0 else 0\n",
    "        reuss_shear_value = 1 / sum_reuss_shear if sum_reuss_shear > 0 else 0\n",
    "        reuss_bulk.append(reuss_bulk_value)\n",
    "        reuss_shear.append(reuss_shear_value)\n",
    "        \n",
    "        df.loc[index, 'Voigt_Bulk'] = sum_voigt_bulk\n",
    "        df.loc[index, 'Reuss_Bulk'] = reuss_bulk_value\n",
    "        df.loc[index, 'Voigt_Shear'] = sum_voigt_shear\n",
    "        df.loc[index, 'Reuss_Shear'] = reuss_shear_value\n",
    "    \n",
    "    df['K_VRH'] = (df['Voigt_Bulk'] + df['Reuss_Bulk']) / 2\n",
    "    df['G_VRH'] = (df['Voigt_Shear'] + df['Reuss_Shear']) / 2\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b5ea833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Data\n",
    "df = pd.read_csv(\"Datasets/Training and Testing data/df.csv\")\n",
    "\n",
    "train_df_vp = pd.read_csv(\"DATASETS/Training and Testing data/train_df_vp.csv\")\n",
    "test_df_vp = pd.read_csv(\"DATASETS/Training and Testing data/test_df_vp.csv\")\n",
    "test_df2_vp = pd.read_csv(\"DATASETS/Training and Testing data/test_df2_vp.csv\")\n",
    "\n",
    "train_df_vs = pd.read_csv(\"DATASETS/Training and Testing data/train_df_vs.csv\")\n",
    "test_df_vs = pd.read_csv(\"DATASETS/Training and Testing data/test_df_vs.csv\")\n",
    "test_df2_vs = pd.read_csv(\"DATASETS/Training and Testing data/test_df2_vs.csv\")\n",
    "\n",
    "formations = pd.read_excel(\"DATASETS/Input data/Rock Formation Depths.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e5538f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating a Dataframe with required rock formation Depths\n",
    "\n",
    "layers = {\n",
    "    \"Layer\": [\n",
    "        \"Eau Claire A-C\", \"Mt. Simon E\", \"Mt. Simon D\", \"Mt. Simon C\",\n",
    "        \"Mt. Simon B\", \"Mt. Simon A\", \"Argenta\", \"Precambrian rhyolite\"\n",
    "    ],\n",
    "    \"Min Value\": [5380, 5552, 5907, 6117, 6428, 6668, 7043, 7162],\n",
    "    \"Max Value\": [5552, 5907, 6117, 6428, 6668, 7043, 7162, 8000],\n",
    "    \"color\": ['grey','purple','purple','purple','purple','purple','red','blue']\n",
    "}\n",
    "formation_depths = pd.DataFrame(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6fc646a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer</th>\n",
       "      <th>Min Value</th>\n",
       "      <th>Max Value</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eau Claire A-C</td>\n",
       "      <td>5380</td>\n",
       "      <td>5552</td>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mt. Simon E</td>\n",
       "      <td>5552</td>\n",
       "      <td>5907</td>\n",
       "      <td>purple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mt. Simon D</td>\n",
       "      <td>5907</td>\n",
       "      <td>6117</td>\n",
       "      <td>purple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mt. Simon C</td>\n",
       "      <td>6117</td>\n",
       "      <td>6428</td>\n",
       "      <td>purple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mt. Simon B</td>\n",
       "      <td>6428</td>\n",
       "      <td>6668</td>\n",
       "      <td>purple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mt. Simon A</td>\n",
       "      <td>6668</td>\n",
       "      <td>7043</td>\n",
       "      <td>purple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Argenta</td>\n",
       "      <td>7043</td>\n",
       "      <td>7162</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Precambrian rhyolite</td>\n",
       "      <td>7162</td>\n",
       "      <td>8000</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Layer  Min Value  Max Value   color\n",
       "0        Eau Claire A-C       5380       5552    grey\n",
       "1           Mt. Simon E       5552       5907  purple\n",
       "2           Mt. Simon D       5907       6117  purple\n",
       "3           Mt. Simon C       6117       6428  purple\n",
       "4           Mt. Simon B       6428       6668  purple\n",
       "5           Mt. Simon A       6668       7043  purple\n",
       "6               Argenta       7043       7162     red\n",
       "7  Precambrian rhyolite       7162       8000    blue"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formation_depths.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9ddd0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feet_to_meters(feet):\n",
    "    return feet * 0.3048\n",
    "\n",
    "test_df_vs['DEPT'] = test_df_vs['DEPT'].apply(feet_to_meters)\n",
    "test_df_vp['DEPT'] = test_df_vp['DEPT'].apply(feet_to_meters)\n",
    "\n",
    "test_df2_vs['DEPT'] = test_df2_vs['DEPT'].apply(feet_to_meters)\n",
    "test_df2_vp['DEPT'] = test_df2_vp['DEPT'].apply(feet_to_meters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "72a525ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "formation_depths['Min Value'] = formation_depths['Min Value'].apply(feet_to_meters)\n",
    "formation_depths['Max Value'] = formation_depths['Max Value'].apply(feet_to_meters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0d7e890",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Layer</th>\n",
       "      <th>Min Value</th>\n",
       "      <th>Max Value</th>\n",
       "      <th>color</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Eau Claire A-C</td>\n",
       "      <td>1639.8240</td>\n",
       "      <td>1692.2496</td>\n",
       "      <td>grey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mt. Simon E</td>\n",
       "      <td>1692.2496</td>\n",
       "      <td>1800.4536</td>\n",
       "      <td>purple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mt. Simon D</td>\n",
       "      <td>1800.4536</td>\n",
       "      <td>1864.4616</td>\n",
       "      <td>purple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mt. Simon C</td>\n",
       "      <td>1864.4616</td>\n",
       "      <td>1959.2544</td>\n",
       "      <td>purple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mt. Simon B</td>\n",
       "      <td>1959.2544</td>\n",
       "      <td>2032.4064</td>\n",
       "      <td>purple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Mt. Simon A</td>\n",
       "      <td>2032.4064</td>\n",
       "      <td>2146.7064</td>\n",
       "      <td>purple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Argenta</td>\n",
       "      <td>2146.7064</td>\n",
       "      <td>2182.9776</td>\n",
       "      <td>red</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Precambrian rhyolite</td>\n",
       "      <td>2182.9776</td>\n",
       "      <td>2438.4000</td>\n",
       "      <td>blue</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Layer  Min Value  Max Value   color\n",
       "0        Eau Claire A-C  1639.8240  1692.2496    grey\n",
       "1           Mt. Simon E  1692.2496  1800.4536  purple\n",
       "2           Mt. Simon D  1800.4536  1864.4616  purple\n",
       "3           Mt. Simon C  1864.4616  1959.2544  purple\n",
       "4           Mt. Simon B  1959.2544  2032.4064  purple\n",
       "5           Mt. Simon A  2032.4064  2146.7064  purple\n",
       "6               Argenta  2146.7064  2182.9776     red\n",
       "7  Precambrian rhyolite  2182.9776  2438.4000    blue"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formation_depths.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206bcca6",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7221d367",
   "metadata": {},
   "source": [
    "## TRAINING FOR VP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8dadbb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'VP'\n",
    "predictor_cols = ['BOUND_WATER','CALCITE','CHLORITE','DOLOMITE',#'HEMATITE',\n",
    "                    'ILLITE','K-FELDSPAR','KAOLINITE','QUARTZ','UWATER']\n",
    "\n",
    "X = train_df_vp[predictor_cols]\n",
    "y = train_df_vp[target_column]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c663a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters found:  {'min_samples_leaf': 2, 'min_samples_split': 5, 'n_estimators': 20}\n",
      "Validation MAE:  155.82420061063885\n",
      "Validation R-squared:  0.945055610646722\n"
     ]
    }
   ],
   "source": [
    "# Define a scoring function\n",
    "scoring = {\n",
    "    'MAE': make_scorer(mean_absolute_error, greater_is_better=False),\n",
    "    'R2': 'r2'\n",
    "}\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [20],  # Number of trees in the forest\n",
    "    'min_samples_split': [5, 10],  # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [2, 4]  # Minimum number of samples required at each leaf node\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring=scoring, refit='R2', return_train_score=True)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "best_rf = grid_search.best_estimator_\n",
    "print('Best parameters found: ', grid_search.best_params_)\n",
    "\n",
    "val_predictions = best_rf.predict(X_val_scaled)\n",
    "val_mae = mean_absolute_error(y_val, val_predictions)\n",
    "val_r2 = r2_score(y_val, val_predictions)\n",
    "print('Validation MAE: ', val_mae)\n",
    "print('Validation R-squared: ', val_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ad507a73",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './../Model Weights/Random Forest for P-Wave Velocity/random_forest_vp.joblib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./../Model Weights/Random Forest for P-Wave Velocity/random_forest_vp.joblib\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 2\u001b[0m joblib\u001b[38;5;241m.\u001b[39mdump(best_rf, filename, compress\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/numpy_pickle.py:548\u001b[0m, in \u001b[0;36mdump\u001b[0;34m(value, filename, compress, protocol, cache_size)\u001b[0m\n\u001b[1;32m    542\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease do not set \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcache_size\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m in joblib.dump, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    543\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthis parameter has no effect and will be removed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    544\u001b[0m                   \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou used \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcache_size=\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(cache_size),\n\u001b[1;32m    545\u001b[0m                   \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m compress_level \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 548\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _write_fileobject(filename, compress\u001b[38;5;241m=\u001b[39m(compress_method,\n\u001b[1;32m    549\u001b[0m                                                compress_level)) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m    550\u001b[0m         NumpyPickler(f, protocol\u001b[38;5;241m=\u001b[39mprotocol)\u001b[38;5;241m.\u001b[39mdump(value)\n\u001b[1;32m    551\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_filename:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/numpy_pickle_utils.py:200\u001b[0m, in \u001b[0;36m_write_fileobject\u001b[0;34m(filename, compress)\u001b[0m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _buffered_write_file(file_instance)\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 200\u001b[0m     file_instance \u001b[38;5;241m=\u001b[39m _COMPRESSORS[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzlib\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mcompressor_file(\n\u001b[1;32m    201\u001b[0m         filename, compresslevel\u001b[38;5;241m=\u001b[39mcompresslevel)\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _buffered_write_file(file_instance)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/compressor.py:107\u001b[0m, in \u001b[0;36mCompressorWrapper.compressor_file\u001b[0;34m(self, fileobj, compresslevel)\u001b[0m\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfileobj_factory(fileobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 107\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfileobj_factory(fileobj, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    108\u001b[0m                                 compresslevel\u001b[38;5;241m=\u001b[39mcompresslevel)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/joblib/compressor.py:287\u001b[0m, in \u001b[0;36mBinaryZlibFile.__init__\u001b[0;34m(self, filename, mode, compresslevel)\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid mode: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (mode,))\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filename, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mopen(filename, mode)\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_closefp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mread\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwrite\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './../Model Weights/Random Forest for P-Wave Velocity/random_forest_vp.joblib'"
     ]
    }
   ],
   "source": [
    "filename = './../Model Weights/Random Forest for P-Wave Velocity/random_forest_vp.joblib'\n",
    "joblib.dump(best_rf, filename, compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c5f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './../Model Weights/Random Forest for P-Wave Velocity/random_forest_vp.joblib'\n",
    "best_rf = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd04a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model on the validation set\n",
    "val_predictions = best_rf.predict(X_val_scaled)\n",
    "val_mae = mean_absolute_error(y_val, val_predictions)\n",
    "val_r2 = r2_score(y_val, val_predictions)\n",
    "\n",
    "print('Validation MAE: ', val_mae)\n",
    "print('Validation R-squared: ', val_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e4d527",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df_vp.drop(['VP', 'RHOZ', 'VOIGT_VP', 'REUSS_VP', 'VRH_VP', 'DEPT', \n",
    "                          'Voigt_Shear', 'Voigt_Bulk', 'Reuss_Shear', 'Reuss_Bulk', \n",
    "                          'K_VRH', 'G_VRH'], axis=1)\n",
    "y_test = test_df_vp['VP']\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "y_test_pred_vp = best_rf.predict(X_test_scaled)\n",
    "y_val_pred = best_rf.predict(X_val_scaled)\n",
    "y_train_pred = best_rf.predict(X_train_scaled)\n",
    "\n",
    "train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "val_rmse = mean_squared_error(y_val, y_val_pred, squared=False)\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred_vp, squared=False)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred_vp)\n",
    "test_r2 = r2_score(y_test, y_test_pred_vp)\n",
    "\n",
    "vrh_rmse = mean_squared_error(y_test, list(test_df_vp['VRH_VP']), squared=False)\n",
    "vrh_mae = mean_absolute_error(y_test, list(test_df_vp['VRH_VP']))\n",
    "vrh_r2 = r2_score(y_test, list(test_df_vp['VRH_VP']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cc5d8a",
   "metadata": {},
   "source": [
    "### 2. Plotting predictions with True Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9627c481",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(21, 7))\n",
    "\n",
    "# Plot for the training set\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "plot_true_vs_predicted(ax1, y_train, y_train_pred, 'Training Set - True vs Predicted')\n",
    "\n",
    "# Plot for the validation set\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "plot_true_vs_predicted(ax2, y_val, y_val_pred, 'Validation Set - True vs Predicted')\n",
    "\n",
    "# Plot for the test set\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "plot_true_vs_predicted(ax3, y_test, y_test_pred_vp, 'Test Set - True vs Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02bc5819",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "plot_true_vs_predicted_v1(ax, y_test, y_test_pred_vp, 'Test Set', 'o', 'red')\n",
    "plot_true_vs_predicted_v1(ax, y_val, y_val_pred, 'Validation Set', 's', 'blue')\n",
    "plot_true_vs_predicted_v1(ax, y_train, y_train_pred, 'Training Set', '^', 'yellow')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e1826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "plot_true_vs_predicted_v2(ax, y_test, y_test_pred_vp, 'Testing Set', 'o', 'red', 0.66, -0.17)\n",
    "plot_true_vs_predicted_v2(ax, y_val, y_val_pred, 'Validation Set', 's', 'blue', 0.4, -0.17)\n",
    "plot_true_vs_predicted_v2(ax, y_train, y_train_pred, 'Training Set', '^', 'yellow', 0.15, -0.17)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ece0a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vpvrh(df):\n",
    "    # (1 GPa = 1e9 Pa)\n",
    "    KVRH = df['K_VRH'] * 1e9\n",
    "    GVRH = df['G_VRH'] * 1e9\n",
    "    \n",
    "    # (1 g/cm^3 = 1000 kg/m^3)\n",
    "    rho = df['RHOZ'] * 1000\n",
    "    \n",
    "    df['VRH_VP'] = np.sqrt((KVRH + 4.0/3.0 * GVRH) / rho)\n",
    "    return df\n",
    "\n",
    "train_df_vp = calculate_vpvrh(train_df_vp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61958ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_true_vs_vrh(ax, true_data, predicted_data, label, marker, color, x_pos, y_pos):\n",
    "    mae = mean_absolute_error(true_data, predicted_data)\n",
    "    r2 = r2_score(true_data, predicted_data)\n",
    "    ax.scatter(true_data, predicted_data, alpha=0.4, label=f'{label}', color=color, marker=marker)\n",
    "    ax.plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'k--', alpha=0.5)\n",
    "    ax.set_xlabel('True Values', fontweight='bold')\n",
    "    ax.set_ylabel('VRH Values', fontweight='bold')\n",
    "    ax.set_title('True vs VRH', fontweight='bold')\n",
    "    plt.xlim(1500, 7200)\n",
    "    plt.ylim(1500, 7200)\n",
    "    # Set text for metrics below the plot area\n",
    "    ax.text(x_pos, y_pos, f'{label} Metrics:\\nMAE: {mae:.2f}\\nR²: {r2:.2f}', transform=ax.transAxes, verticalalignment='top', horizontalalignment='left', fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=color, facecolor='white'))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "plot_true_vs_vrh(ax, df['VP'], df['VRH_VP'], 'VRH', 'o', 'pink', 0.66, -0.17)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7441ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "plot_true_vs_predicted_v2(ax, y_test, y_test_pred_vp, 'Testing Set', 'o', 'red', 0.66, -0.17)\n",
    "plot_true_vs_vrh(ax, y_test, test_df_vp['VRH_VP'], 'VRH', 'o', 'pink', 0.66, -0.17)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6de17d0",
   "metadata": {},
   "source": [
    "### 3. Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2355dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results('P-Wave Velocity [m/s]', test_df_vp, y_test_pred_vp, y_test, 'VOIGT_VP', 'REUSS_VP','VRH_VP', 0, 7500, 2200, 1550)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d95da5f",
   "metadata": {},
   "source": [
    "## TRAINING FOR VS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc09ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'VS'\n",
    "predictor_cols = ['BOUND_WATER','CALCITE','CHLORITE','DOLOMITE',\n",
    "                  'ILLITE','K-FELDSPAR','KAOLINITE','QUARTZ','UWATER']\n",
    "\n",
    "X = train_df_vs[predictor_cols]\n",
    "y = train_df_vs[target_column]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=4)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "joblib.dump(model, './../Model Weights/Random Forest for S-Wave Velocity/random_forest_vs.joblib', compress=3)\n",
    "\n",
    "train_predictions = model.predict(X_train_scaled)\n",
    "val_predictions = model.predict(X_val_scaled)\n",
    "\n",
    "X_test = test_df_vs.drop(['VS', 'RHOZ', 'VOIGT_VS', 'REUSS_VS', 'VRH_VS', 'DEPT', \n",
    "                          'Voigt_Shear', 'Voigt_Bulk', 'Reuss_Shear', 'Reuss_Bulk', \n",
    "                          'K_VRH', 'G_VRH'], axis=1)\n",
    "y_test = test_df_vs['VS']\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "test_predictions = model.predict(X_test_scaled)\n",
    "\n",
    "plt.figure(figsize=(21, 7))\n",
    "\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "plot_true_vs_predicted(ax1, y_train, train_predictions, 'Training Set - True vs Predicted')\n",
    "\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "plot_true_vs_predicted(ax2, y_val, val_predictions, 'Validation Set - True vs Predicted')\n",
    "\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "plot_true_vs_predicted(ax3, y_test, test_predictions, 'Test Set - True vs Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "train_rmse = mean_squared_error(y_train, train_predictions, squared=False)\n",
    "train_mae = mean_absolute_error(y_train, train_predictions)\n",
    "train_r2 = r2_score(y_train, train_predictions)\n",
    "\n",
    "val_rmse = mean_squared_error(y_val, val_predictions, squared=False)\n",
    "val_mae = mean_absolute_error(y_val, val_predictions)\n",
    "val_r2 = r2_score(y_val, val_predictions)\n",
    "\n",
    "test_rmse = mean_squared_error(y_test, test_predictions, squared=False)\n",
    "test_mae = mean_absolute_error(y_test, test_predictions)\n",
    "test_r2 = r2_score(y_test, test_predictions)\n",
    "\n",
    "vrh_rmse = mean_squared_error(y_test, list(test_df_vs['VRH_VS']), squared=False)\n",
    "vrh_mae = mean_absolute_error(y_test, list(test_df_vs['VRH_VS']))\n",
    "vrh_r2 = r2_score(y_test, list(test_df_vs['VRH_VS']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9874018e",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d71c8ff9",
   "metadata": {},
   "source": [
    "## TRAINING FOR VP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ef5688",
   "metadata": {},
   "source": [
    "### 1. Building and Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57c888e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'VP'\n",
    "predictor_cols = ['BOUND_WATER','CALCITE','CHLORITE','DOLOMITE',#'HEMATITE',\n",
    "                    'ILLITE','K-FELDSPAR','KAOLINITE','QUARTZ','UWATER']\n",
    "\n",
    "X = train_df_vp[predictor_cols]\n",
    "y = train_df_vp[target_column]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478be29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Neural Network with added complexity\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(len(predictor_cols), 256)  \n",
    "        self.fc2 = nn.Linear(256, 64) \n",
    "        self.fc4 = nn.Linear(64, 1)  \n",
    "        self.relu = nn.ReLU()  # Activation function\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train_scaled.astype(np.float32))\n",
    "y_train_tensor = torch.tensor(y_train.values.astype(np.float32))\n",
    "X_val_tensor = torch.tensor(X_val_scaled.astype(np.float32))\n",
    "y_val_tensor = torch.tensor(y_val.values.astype(np.float32))\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor.view(-1, 1))\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor.view(-1, 1))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Criterion for loss (still needed for the gradient computation)\n",
    "criterion = nn.MSELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  \n",
    "\n",
    "num_epochs = 100\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_mae = 0\n",
    "    total_r2 = 0\n",
    "    count = 0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Computing MAE and R-squared for the current batch\n",
    "        mae = mean_absolute_error(targets.detach().numpy(), outputs.detach().numpy())\n",
    "        r2 = r2_score(targets.detach().numpy(), outputs.detach().numpy())\n",
    "        total_mae += mae\n",
    "        total_r2 += r2\n",
    "        count += 1\n",
    "    \n",
    "    # Computing the average MAE and R-squared over all batches\n",
    "    avg_mae = total_mae / count\n",
    "    avg_r2 = total_r2 / count\n",
    "    if((epoch+1)%10==0 or epoch==0):\n",
    "        print(f'Epoch {epoch+1}, MAE: {avg_mae:.4f}, R-squared: {avg_r2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5846afa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model weights\n",
    "joblib.dump(model, './../Model weights/Neural Network for P-Wave Velocity/nn_vp.joblib')\n",
    "print(\"Model weights saved as 'nn_vp.joblib'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51829a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './../Model weights/Neural Network for P-Wave Velocity/nn_vp.joblib'\n",
    "model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a87d697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SET PREDICTIONS\n",
    "X_test = test_df_vp.drop(['VP', 'RHOZ', 'VOIGT_VP', 'REUSS_VP', 'VRH_VP', 'DEPT', \n",
    "                          'Voigt_Shear', 'Voigt_Bulk', 'Reuss_Shear', 'Reuss_Bulk', \n",
    "                          'K_VRH', 'G_VRH'], axis=1)\n",
    "y_test = test_df_vp['VP']\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa67a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Predictions\n",
    "X_test_tensor = torch.tensor(X_test_scaled.astype(np.float32))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_test_tensor)\n",
    "    test_predictions_np = test_predictions.numpy().flatten()\n",
    "    print(\"Predictions:\", test_predictions_np)\n",
    "    \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_predictions = model(X_train_tensor)\n",
    "    train_predictions_np = train_predictions.numpy().flatten()\n",
    "    print(\"Predictions:\", train_predictions_np)\n",
    "    \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_predictions = model(X_val_tensor)\n",
    "    val_predictions_np = val_predictions.numpy().flatten()\n",
    "    print(\"Predictions:\", val_predictions_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c815e33c",
   "metadata": {},
   "source": [
    "### 2. Plotting predictions with True Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30122e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(21, 7))\n",
    "\n",
    "# Plot for the training set\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "plot_true_vs_predicted(ax1, y_train, train_predictions_np, 'Training Set - True vs Predicted')\n",
    "\n",
    "# Plot for the validation set\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "plot_true_vs_predicted(ax2, y_val, val_predictions_np, 'Validation Set - True vs Predicted')\n",
    "\n",
    "# Plot for the test set\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "plot_true_vs_predicted(ax3, y_test, test_predictions_np, 'Test Set - True vs Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b36dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_true_vs_predicted_v1(ax, true_data, predicted_data, label, marker, color):\n",
    "    ax.scatter(true_data, predicted_data, alpha=0.7, label=label, marker=marker, color=color)\n",
    "    ax.plot([true_data.min(), true_data.max()], [true_data.min(), true_data.max()], 'k--', alpha=0.5)\n",
    "    ax.set_xlabel('True Values', fontweight='bold')\n",
    "    ax.set_ylabel('Predicted Values', fontweight='bold')\n",
    "    ax.set_title('True vs Predicted', fontweight='bold')\n",
    "    ax.legend()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "plot_true_vs_predicted_v1(ax, y_test, test_predictions_np, 'Test Set', 'o', 'red')\n",
    "plot_true_vs_predicted_v1(ax, y_val, val_predictions_np, 'Validation Set', 's', 'blue')\n",
    "plot_true_vs_predicted_v1(ax, y_train, train_predictions_np, 'Training Set', '^', 'yellow')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf01659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_true_vs_predicted_v2(ax, true_data, predicted_data, label, marker, color, x_pos, y_pos):\n",
    "    mae = mean_absolute_error(true_data, predicted_data)\n",
    "    r2 = r2_score(true_data, predicted_data)\n",
    "    ax.scatter(true_data, predicted_data, alpha=0.5, label=f'{label}', color=color, marker=marker)\n",
    "    ax.plot([true_data.min(), true_data.max()], [true_data.min(), true_data.max()], 'k--', alpha=0.5)\n",
    "    ax.set_xlabel('True Values', fontweight='bold')\n",
    "    ax.set_ylabel('Predicted Values', fontweight='bold')\n",
    "    ax.set_title('True vs Predicted', fontweight='bold')\n",
    "    # Set text for metrics below the plot area\n",
    "    ax.text(x_pos, y_pos, f'{label} Metrics:\\nMAE: {mae:.2f}\\nR²: {r2:.2f}', transform=ax.transAxes, verticalalignment='top', horizontalalignment='left', fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=color, facecolor='white'))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "# Adjust x_pos and y_pos for each dataset to display metrics in one horizontal line below the graph\n",
    "plot_true_vs_predicted_v2(ax, y_test, test_predictions_np, 'Testing Set', 'o', 'red', 0.66, -0.17)\n",
    "plot_true_vs_predicted_v2(ax, y_val, val_predictions_np, 'Validation Set', 's', 'blue', 0.4, -0.17)\n",
    "plot_true_vs_predicted_v2(ax, y_train, train_predictions_np, 'Training Set', '^', 'yellow', 0.15, -0.17)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb5c161",
   "metadata": {},
   "source": [
    "### 3. Comparing Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0838ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error metrics for the training set\n",
    "train_rmse = mean_squared_error(y_train, train_predictions_np, squared=False)\n",
    "train_mae = mean_absolute_error(y_train, train_predictions_np)\n",
    "train_r2 = r2_score(y_train, train_predictions_np)\n",
    "\n",
    "# Calculate error metrics for the validation set\n",
    "val_rmse = mean_squared_error(y_val, val_predictions_np, squared=False)\n",
    "val_mae = mean_absolute_error(y_val, val_predictions_np)\n",
    "val_r2 = r2_score(y_val, val_predictions_np)\n",
    "\n",
    "# Calculate error metrics for the Test set\n",
    "test_rmse = mean_squared_error(y_test, test_predictions_np, squared=False)\n",
    "test_mae = mean_absolute_error(y_test, test_predictions_np)\n",
    "test_r2 = r2_score(y_test, test_predictions_np)\n",
    "\n",
    "# Calculate metrics for the VRH values\n",
    "vrh_rmse = mean_squared_error(y_test, list(test_df_vp['VRH_VP']), squared=False)\n",
    "vrh_mae = mean_absolute_error(y_test, list(test_df_vp['VRH_VP']))\n",
    "vrh_r2 = r2_score(y_test, list(test_df_vp['VRH_VP']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415892a5",
   "metadata": {},
   "source": [
    "### 4. Plotting Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e470a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_results('P-Wave Velocity [m/s]', test_df_vp, test_predictions_np, y_test, 'VOIGT_VP', 'REUSS_VP','VRH_VP', 0, 7500, 2200, 1550)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5eb580e",
   "metadata": {},
   "source": [
    "## TRAINING FOR VS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb77f074",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'VS'\n",
    "predictor_cols = ['BOUND_WATER','CALCITE','CHLORITE','DOLOMITE',#'HEMATITE',\n",
    "                    'ILLITE','K-FELDSPAR','KAOLINITE','QUARTZ','UWATER']\n",
    "\n",
    "X = train_df_vs[predictor_cols]\n",
    "y = train_df_vs[target_column]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19adacb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the Neural Network with added complexity\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(len(predictor_cols), 256)  \n",
    "        self.fc2 = nn.Linear(256, 64) \n",
    "        self.fc4 = nn.Linear(64, 1)  \n",
    "        self.relu = nn.ReLU()  # Activation function\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n",
    "model = Net()\n",
    "\n",
    "# Assume X_train_scaled, y_train, X_val_scaled, y_val are defined elsewhere\n",
    "# Prepare Data for PyTorch\n",
    "X_train_tensor = torch.tensor(X_train_scaled.astype(np.float32))\n",
    "y_train_tensor = torch.tensor(y_train.values.astype(np.float32))\n",
    "X_val_tensor = torch.tensor(X_val_scaled.astype(np.float32))\n",
    "y_val_tensor = torch.tensor(y_val.values.astype(np.float32))\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor.view(-1, 1))\n",
    "val_dataset = TensorDataset(X_val_tensor, y_val_tensor.view(-1, 1))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Criterion for loss (still needed for the gradient computation)\n",
    "criterion = nn.MSELoss()  \n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  \n",
    "\n",
    "num_epochs = 500\n",
    "\n",
    "model.train()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_mae = 0\n",
    "    total_r2 = 0\n",
    "    count = 0\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Computing MAE and R-squared for the current batch\n",
    "        mae = mean_absolute_error(targets.detach().numpy(), outputs.detach().numpy())\n",
    "        r2 = r2_score(targets.detach().numpy(), outputs.detach().numpy())\n",
    "        total_mae += mae\n",
    "        total_r2 += r2\n",
    "        count += 1\n",
    "    \n",
    "    # Computing the average MAE and R-squared over all batches\n",
    "    avg_mae = total_mae / count\n",
    "    avg_r2 = total_r2 / count\n",
    "    if((epoch+1)%10==0 or epoch==0):\n",
    "        print(f'Epoch {epoch+1}, MAE: {avg_mae:.4f}, R-squared: {avg_r2:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea3ad84",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(model, './../Model weights/Neural Network for S-Wave Velocity/nn_vs.joblib')\n",
    "print(\"Model weights saved as 'nn_vs.joblib'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f5d749",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './../Model weights/Neural Network for S-Wave Velocity/nn_vs.joblib'\n",
    "model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d131b166",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SET PREDICTIONS\n",
    "X_test = test_df_vs.drop(['VS', 'RHOZ', 'VOIGT_VS', 'REUSS_VS', 'VRH_VS', 'DEPT', \n",
    "                          'Voigt_Shear', 'Voigt_Bulk', 'Reuss_Shear', 'Reuss_Bulk', \n",
    "                          'K_VRH', 'G_VRH'], axis=1)\n",
    "y_test = test_df_vs['VS']\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e555645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making Predictions\n",
    "X_test_tensor = torch.tensor(X_test_scaled.astype(np.float32))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    test_predictions = model(X_test_tensor)\n",
    "    test_predictions_np = test_predictions.numpy().flatten()\n",
    "    print(\"Predictions:\", test_predictions_np)\n",
    "    \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    train_predictions = model(X_train_tensor)\n",
    "    train_predictions_np = train_predictions.numpy().flatten()\n",
    "    print(\"Predictions:\", train_predictions_np)\n",
    "    \n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_predictions = model(X_val_tensor)\n",
    "    val_predictions_np = val_predictions.numpy().flatten()\n",
    "    print(\"Predictions:\", val_predictions_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf89e3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(21, 7))\n",
    "\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "plot_true_vs_predicted(ax1, y_train, train_predictions_np, 'Training Set - True vs Predicted')\n",
    "\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "plot_true_vs_predicted(ax2, y_val, val_predictions_np, 'Validation Set - True vs Predicted')\n",
    "\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "plot_true_vs_predicted(ax3, y_test, test_predictions_np, 'Test Set - True vs Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9266f4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error metrics for the training set\n",
    "train_rmse = mean_squared_error(y_train, train_predictions_np, squared=False)\n",
    "train_mae = mean_absolute_error(y_train, train_predictions_np)\n",
    "train_r2 = r2_score(y_train, train_predictions_np)\n",
    "\n",
    "# Calculate error metrics for the validation set\n",
    "val_rmse = mean_squared_error(y_val, val_predictions_np, squared=False)\n",
    "val_mae = mean_absolute_error(y_val, val_predictions_np)\n",
    "val_r2 = r2_score(y_val, val_predictions_np)\n",
    "\n",
    "# Calculate error metrics for the Test set\n",
    "test_rmse = mean_squared_error(y_test, test_predictions_np, squared=False)\n",
    "test_mae = mean_absolute_error(y_test, test_predictions_np)\n",
    "test_r2 = r2_score(y_test, test_predictions_np)\n",
    "\n",
    "# Calculate metrics for the VRH values\n",
    "vrh_rmse = mean_squared_error(y_test, list(test_df_vs['VRH_VS']), squared=False)\n",
    "vrh_mae = mean_absolute_error(y_test, list(test_df_vs['VRH_VS']))\n",
    "vrh_r2 = r2_score(y_test, list(test_df_vs['VRH_VS']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba51df3",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f6b251",
   "metadata": {},
   "source": [
    "### 1. Training for Vp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a8e46df",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_vp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d2fd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'VP'\n",
    "predictor_cols = ['BOUND_WATER','CALCITE','CHLORITE','DOLOMITE',#'HEMATITE',\n",
    "                    'ILLITE','K-FELDSPAR','KAOLINITE','QUARTZ','UWATER']\n",
    "\n",
    "X = train_df_vp[predictor_cols]\n",
    "y = train_df_vp[target_column]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ff79c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample': [0.7, 1],\n",
    "    'colsample_bytree': [0.7, 1],\n",
    "    'reg_alpha': [ 0.1]\n",
    "}\n",
    "\n",
    "xgb_model = XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', verbose=1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_val_pred = best_model.predict(X_val_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845fc761",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Model weights/XGBoost for P-Wave Velocity/best_xgb_model.joblib'\n",
    "joblib.dump(best_model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23ea31b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Model weights/XGBoost for P-Wave Velocity/best_xgb_model.joblib'\n",
    "best_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67498d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = best_model.predict(X_val_scaled)\n",
    "y_train_pred = best_model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555eaf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f6a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SET PREDICTIONS\n",
    "X_test = test_df_vp.drop(['VP', 'RHOZ', 'VOIGT_VP', 'REUSS_VP', 'VRH_VP', 'DEPT', \n",
    "                          'Voigt_Shear', 'Voigt_Bulk', 'Reuss_Shear', 'Reuss_Bulk', \n",
    "                          'K_VRH', 'G_VRH'], axis=1)\n",
    "y_test = test_df_vp['VP']\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fcd175",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_vp = best_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea29c82",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate error metrics for the training set\n",
    "train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate error metrics for the validation set\n",
    "val_rmse = mean_squared_error(y_val, y_val_pred, squared=False)\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Calculate error metrics for the test set\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred_vp, squared=False)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred_vp)\n",
    "test_r2 = r2_score(y_test, y_test_pred_vp)\n",
    "\n",
    "# Calculate metrics for the VRH values\n",
    "vrh_rmse = mean_squared_error(y_test, list(test_df_vp['VRH_VP']), squared=False)\n",
    "vrh_mae = mean_absolute_error(y_test, list(test_df_vp['VRH_VP']))\n",
    "vrh_r2 = r2_score(y_test, list(test_df_vp['VRH_VP']))\n",
    "\n",
    "fig = create_metrics_table_plotly(train_rmse, train_mae, train_r2, val_rmse, val_mae, val_r2, test_rmse, test_mae, test_r2, vrh_rmse, vrh_mae, vrh_r2)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8887ff",
   "metadata": {},
   "source": [
    "1. **Root Mean Square Error (RMSE):** This measures the average magnitude of the errors between the predicted values from the model and the actual values. It squares the errors before averaging to give more weight to larger errors. The RMSE for the training data is quite low at around 73.73, which suggests that the model fits the training data well. However, the RMSE for the validation data is much higher at approximately 226.88, indicating that the model doesn’t perform as well on the validation set.\n",
    "\n",
    "2. **Mean Absolute Error (MAE):** This metric calculates the average absolute difference between the predicted values and the actual values. Unlike RMSE, MAE doesn’t square the errors, so it doesn’t penalize larger errors as heavily. The MAE is lower than the RMSE in both training (approximately 54.76) and validation (approximately 154.55), which is typically the case. However, the jump in error from training to validation suggests that the model might not generalize well to unseen data.\n",
    "\n",
    "3. **R-squared (R²):** This is a statistical measure of how close the data are to the fitted regression line. It is also known as the coefficient of determination. The R² for both training and validation is quite high (close to 1), with training at about 0.995 and validation at about 0.948. This suggests that the model explains a large proportion of the variance in the outcome variable for both training and validation datasets.\n",
    "\n",
    "However, the significantly higher RMSE and MAE for the validation data compared to the training data indicate that the model might be overfitting to the training data. Overfitting occurs when a model learns the training data too well, including the noise and outliers, which then harms its performance on new, unseen data.\n",
    "\n",
    "In summary, model seems to be performing well on the training data but not as well on the validation data. This discrepancy suggests that the model may not generalize well to new data, likely due to overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e90bd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(21, 7))\n",
    "\n",
    "# Plot for the training set\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "plot_true_vs_predicted(ax1, y_train, y_train_pred, 'Training Set - True vs Predicted')\n",
    "\n",
    "# Plot for the validation set\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "plot_true_vs_predicted(ax2, y_val, y_val_pred, 'Validation Set - True vs Predicted')\n",
    "\n",
    "# Plot for the test set\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "plot_true_vs_predicted(ax3, y_test, y_test_pred_vp, 'Test Set - True vs Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc061a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results('P-Wave Velocity [m/s]', test_df_vp, y_test_pred_vp, y_test, 'VOIGT_VP', 'REUSS_VP','VRH_VP', 0, 7500, 2200, 1550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944204d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_true_vs_predicted_v1(ax, true_data, predicted_data, label, marker, color):\n",
    "    ax.scatter(true_data, predicted_data, alpha=0.7, label=label, marker=marker, color=color)\n",
    "    ax.plot([true_data.min(), true_data.max()], [true_data.min(), true_data.max()], 'k--', alpha=0.5)\n",
    "    ax.set_xlabel('True Values', fontweight='bold')\n",
    "    ax.set_ylabel('Predicted Values', fontweight='bold')\n",
    "    ax.set_title('True vs Predicted', fontweight='bold')\n",
    "    ax.legend()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "plot_true_vs_predicted_v1(ax, y_test, y_test_pred_vp, 'Test Set', 'o', 'red')\n",
    "plot_true_vs_predicted_v1(ax, y_val, y_val_pred, 'Validation Set', 's', 'blue')\n",
    "plot_true_vs_predicted_v1(ax, y_train, y_train_pred, 'Training Set', '^', 'yellow')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4915a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_true_vs_predicted_v2(ax, true_data, predicted_data, label, marker, color, x_pos, y_pos):\n",
    "    mae = mean_absolute_error(true_data, predicted_data)\n",
    "    r2 = r2_score(true_data, predicted_data)\n",
    "    ax.scatter(true_data, predicted_data, alpha=0.5, label=f'{label}', color=color, marker=marker)\n",
    "    ax.plot([true_data.min(), true_data.max()], [true_data.min(), true_data.max()], 'k--', alpha=0.5)\n",
    "    ax.set_xlabel('True Values', fontweight='bold')\n",
    "    ax.set_ylabel('Predicted Values', fontweight='bold')\n",
    "    ax.set_title('True vs Predicted', fontweight='bold')\n",
    "    # Set text for metrics below the plot area\n",
    "    ax.text(x_pos, y_pos, f'{label} Metrics:\\nMAE: {mae:.2f}\\nR²: {r2:.2f}', transform=ax.transAxes, verticalalignment='top', horizontalalignment='left', fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=color, facecolor='white'))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "# Adjust x_pos and y_pos for each dataset to display metrics in one horizontal line below the graph\n",
    "plot_true_vs_predicted_v2(ax, y_test, y_test_pred_vp, 'Testing Set', 'o', 'red', 0.66, -0.17)\n",
    "plot_true_vs_predicted_v2(ax, y_val, y_val_pred, 'Validation Set', 's', 'blue', 0.4, -0.17)\n",
    "plot_true_vs_predicted_v2(ax, y_train, y_train_pred, 'Training Set', '^', 'yellow', 0.15, -0.17)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804e7075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "\n",
    "def plot_true_vs_predicted_v2(ax, true_data, predicted_data, label, marker, color, x_pos, y_pos):\n",
    "    mae = mean_absolute_error(true_data, predicted_data)\n",
    "    r2 = r2_score(true_data, predicted_data)\n",
    "    ax.scatter(true_data, predicted_data, alpha=0.5, label=f'{label}', color=color, marker=marker)\n",
    "    ax.plot([true_data.min(), true_data.max()], [true_data.min(), true_data.max()], 'k--', alpha=0.5)\n",
    "    ax.set_xlabel('True Values', fontweight='bold')\n",
    "    ax.set_ylabel('Predicted Values', fontweight='bold')\n",
    "    ax.set_title('True vs Predicted', fontweight='bold')\n",
    "    # Set text for metrics on the right of the plot area\n",
    "    ax.text(x_pos, y_pos, f'{label} Metrics:\\nMAE: {mae:.2f}\\nR²: {r2:.2f}', transform=ax.transAxes, verticalalignment='center', horizontalalignment='left', fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=color, facecolor='white'))\n",
    "\n",
    "plt.figure(figsize=(10, 6))  # Adjust the figure size to ensure there is enough space for the text\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "# Fixed x_pos beyond 1 for right-side display and adjusted y_pos for vertical alignment\n",
    "plot_true_vs_predicted_v2(ax, y_test, y_test_pred_vp, 'Testing Set', 'o', 'red', 1.1, 0.30)\n",
    "plot_true_vs_predicted_v2(ax, y_val, y_val_pred, 'Validation Set', 's', 'blue', 1.1, 0.45)\n",
    "plot_true_vs_predicted_v2(ax, y_train, y_train_pred, 'Training Set', '^', 'yellow', 1.1, 0.6)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 0.8, 1])  # Adjust the layout to prevent clipping of text\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37d0f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Metrics\n",
    "metrics = ['RMSE', 'MAE']\n",
    "train_metrics = [train_rmse, train_mae]\n",
    "val_metrics = [val_rmse, val_mae]\n",
    "test_metrics = [test_rmse, test_mae]\n",
    "vrh_metrics = [vrh_rmse, vrh_mae]  # Example: Replace these with actual values if they exist\n",
    "\n",
    "n_groups = 2\n",
    "index = np.arange(n_groups)\n",
    "bar_width = 0.2\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "train_bar = ax.bar(index, train_metrics, bar_width, label='Train')\n",
    "val_bar = ax.bar(index + bar_width, val_metrics, bar_width, label='Validation')\n",
    "test_bar = ax.bar(index + 2 * bar_width, test_metrics, bar_width, label='Test')\n",
    "vrh_bar = ax.bar(index + 3 * bar_width, vrh_metrics, bar_width, label='VRH')  # Adjust label as needed\n",
    "\n",
    "\n",
    "ax.set_xlabel('Metrics')\n",
    "ax.set_ylabel('Values')\n",
    "ax.set_title('Error Metrics by Dataset')\n",
    "ax.set_xticks(index + 1.5 * bar_width)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db78c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "plot_true_vs_predicted_v1(ax1, y_train, y_train_pred, 'Training Set', 'o', 'green')\n",
    "\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "plot_true_vs_predicted_v1(ax2, y_val, y_val_pred, 'Validation Set', 's', 'blue')\n",
    "\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "plot_true_vs_predicted_v1(ax3, y_test, y_test_pred_vp, 'Test Set', 'x', 'red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1670d87",
   "metadata": {},
   "source": [
    "### 2. Training for Vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1782be65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_vs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d75d349",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = 'VS'\n",
    "predictor_cols = ['BOUND_WATER','CALCITE','CHLORITE','DOLOMITE',#'HEMATITE',\n",
    "                    'ILLITE','K-FELDSPAR','KAOLINITE','QUARTZ','UWATER']\n",
    "\n",
    "X = train_df_vs[predictor_cols]\n",
    "y = train_df_vs[target_column]\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473700fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'subsample': [0.7, 1],\n",
    "    'colsample_bytree': [0.7, 1],\n",
    "    'reg_alpha': [ 0.1]\n",
    "}\n",
    "\n",
    "xgb_model = XGBRegressor(objective='reg:squarederror')\n",
    "\n",
    "grid_search = GridSearchCV(estimator=xgb_model, \n",
    "                           param_grid=param_grid, \n",
    "                           cv=5, \n",
    "                           scoring='neg_mean_squared_error', \n",
    "                           verbose=1)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(f\"Best parameters found: {grid_search.best_params_}\")\n",
    "\n",
    "best_model = grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82296007",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Model weights/XGBoost for S-Wave Velocity/best1_xgb_model.joblib'\n",
    "joblib.dump(best_model, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6c4354",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Model weights/XGBoost for S-Wave Velocity/best1_xgb_model.joblib'\n",
    "best_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c07af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST SET\n",
    "X_test = test_df_vs.drop(['VS', 'RHOZ', 'VOIGT_VS', 'REUSS_VS', 'VRH_VS', 'DEPT', \n",
    "                          'Voigt_Shear', 'Voigt_Bulk', 'Reuss_Shear', 'Reuss_Bulk', \n",
    "                          'K_VRH', 'G_VRH'], axis=1)\n",
    "y_test = test_df_vs['VS']\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530593d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_pred = best_model.predict(X_val_scaled)\n",
    "y_train_pred = best_model.predict(X_train_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1b419a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_vs = best_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a685616e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(21, 7))\n",
    "\n",
    "# Plot for the training set\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "plot_true_vs_predicted(ax1, y_train, y_train_pred, 'Training Set - True vs Predicted')\n",
    "\n",
    "# Plot for the validation set\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "plot_true_vs_predicted(ax2, y_val, y_val_pred, 'Validation Set - True vs Predicted')\n",
    "\n",
    "# Plot for the test set\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "plot_true_vs_predicted(ax3, y_test, y_test_pred_vs, 'Test Set - True vs Predicted')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2004f868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate error metrics for the training set\n",
    "train_rmse = mean_squared_error(y_train, y_train_pred, squared=False)\n",
    "train_mae = mean_absolute_error(y_train, y_train_pred)\n",
    "train_r2 = r2_score(y_train, y_train_pred)\n",
    "\n",
    "# Calculate error metrics for the validation set\n",
    "val_rmse = mean_squared_error(y_val, y_val_pred, squared=False)\n",
    "val_mae = mean_absolute_error(y_val, y_val_pred)\n",
    "val_r2 = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Calculate error metrics for the test set\n",
    "test_rmse = mean_squared_error(y_test, y_test_pred_vs, squared=False)\n",
    "test_mae = mean_absolute_error(y_test, y_test_pred_vs)\n",
    "test_r2 = r2_score(y_test, y_test_pred_vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81236c61",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_results('S-Wave Velocity [m/s]', test_df_vs, y_test_pred_vs, y_test, 'VOIGT_VS', 'REUSS_VS','VRH_VS', 0, 5000, 2200, 1550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb100c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "ax1 = plt.subplot(1, 3, 1)\n",
    "plot_true_vs_predicted_v1(ax1, y_train, y_train_pred, 'Training Set', 'o', 'green')\n",
    "\n",
    "ax2 = plt.subplot(1, 3, 2)\n",
    "plot_true_vs_predicted_v1(ax2, y_val, y_val_pred, 'Validation Set', 's', 'blue')\n",
    "\n",
    "ax3 = plt.subplot(1, 3, 3)\n",
    "plot_true_vs_predicted_v1(ax3, y_test, y_test_pred_vs, 'Test Set', 'x', 'red')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42364f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_true_vs_predicted_v1(ax, true_data, predicted_data, label, marker, color):\n",
    "    ax.scatter(true_data, predicted_data, alpha=0.7, label=label, marker=marker, color=color)\n",
    "    ax.plot([true_data.min(), true_data.max()], [true_data.min(), true_data.max()], 'k--', alpha=0.5)\n",
    "    ax.set_xlabel('True Values', fontweight='bold')\n",
    "    ax.set_ylabel('Predicted Values', fontweight='bold')\n",
    "    ax.set_title('True vs Predicted', fontweight='bold')\n",
    "    ax.legend()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "plot_true_vs_predicted_v1(ax, y_test, y_test_pred_vs, 'Test Set', 'o', 'red')\n",
    "plot_true_vs_predicted_v1(ax, y_val, y_val_pred, 'Validation Set', 's', 'blue')\n",
    "plot_true_vs_predicted_v1(ax, y_train, y_train_pred, 'Training Set', '^', 'yellow')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e2583a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_true_vs_predicted_v2(ax, true_data, predicted_data, label, marker, color, x_pos, y_pos):\n",
    "    mae = mean_absolute_error(true_data, predicted_data)\n",
    "    r2 = r2_score(true_data, predicted_data)\n",
    "    ax.scatter(true_data, predicted_data, alpha=0.5, label=f'{label}', color=color, marker=marker)\n",
    "    ax.plot([true_data.min(), true_data.max()], [true_data.min(), true_data.max()], 'k--', alpha=0.5)\n",
    "    ax.set_xlabel('True Values', fontweight='bold')\n",
    "    ax.set_ylabel('Predicted Values', fontweight='bold')\n",
    "    ax.set_title('True vs Predicted', fontweight='bold')\n",
    "    # Set text for metrics below the plot area\n",
    "    ax.text(x_pos, y_pos, f'{label} Metrics:\\nMAE: {mae:.2f}\\nR²: {r2:.2f}', transform=ax.transAxes, verticalalignment='top', horizontalalignment='left', fontsize=10, bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=color, facecolor='white'))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "ax = plt.subplot(1, 1, 1)\n",
    "\n",
    "# Adjust x_pos and y_pos for each dataset to display metrics in one horizontal line below the graph\n",
    "plot_true_vs_predicted_v2(ax, y_test, y_test_pred_vs, 'Testing Set', 'o', 'red', 0.66, -0.17)\n",
    "plot_true_vs_predicted_v2(ax, y_val, y_val_pred, 'Validation Set', 's', 'blue', 0.4, -0.17)\n",
    "plot_true_vs_predicted_v2(ax, y_train, y_train_pred, 'Training Set', '^', 'yellow', 0.15, -0.17)\n",
    "\n",
    "plt.tight_layout(rect=[0, 0.1, 1, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5171cdc",
   "metadata": {},
   "source": [
    "## Calculating K and G from predicted Vp and Vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bb486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_vp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956e2adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_vp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c05ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test_pred_vp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778b556d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'DEPT': test_df_vp['DEPT'],\n",
    "    'y_test_pred_vs': y_test_pred_vs,\n",
    "    'y_test_pred_vp': y_test_pred_vp,\n",
    "    'RHOZ': test_df_vp['RHOZ'],\n",
    "    'Voigt_Bulk': test_df_vp['Voigt_Bulk'],\n",
    "    'Reuss_Bulk': test_df_vp['Reuss_Bulk'],\n",
    "    'Voigt_Shear': test_df_vp['Voigt_Shear'],\n",
    "    'Reuss_Shear': test_df_vp['Reuss_Shear'],\n",
    "    'K_VRH': test_df_vp['K_VRH'],\n",
    "    'G_VRH': test_df_vp['G_VRH'],\n",
    "    'VP': test_df_vp['VP'],\n",
    "    'VS': test_df_vs['VS'],\n",
    "}\n",
    "\n",
    "df_kg = pd.DataFrame(data)\n",
    "\n",
    "df_kg['G_pred'] = ((df_kg['RHOZ']*1000) * df_kg['y_test_pred_vs']**2)/ 1e9\n",
    "df_kg['K_pred'] = ((df_kg['RHOZ']*1000) * (df_kg['y_test_pred_vp']**2 - (4/3) * df_kg['y_test_pred_vs']**2))/ 1e9\n",
    "\n",
    "df_kg['G'] = ((df_kg['RHOZ']*1000) * df_kg['VS']**2)/ 1e9\n",
    "df_kg['K'] = ((df_kg['RHOZ']*1000) * (df_kg['VP']**2 - (4/3) * df_kg['VS']**2))/ 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49ec0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccfb175",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results('Bulk Modulus [GPa]', df_kg, df_kg['K_pred'], df_kg['K'], 'Voigt_Bulk', 'Reuss_Bulk','K_VRH', 0, 75, 2200, 1660, 'yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836532b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results('Shear Modulus [GPa]', df_kg, df_kg['G_pred'], df_kg['G'], 'Voigt_Shear', 'Reuss_Shear','G_VRH', 0, 60, 2200, 1660, 'yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364b25bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking our Results\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7378f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_df_vp[test_df_vp['DEPT']>1800].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf2a163",
   "metadata": {},
   "source": [
    "## Double Checking our model on VW2 Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff92d99",
   "metadata": {},
   "source": [
    "### 1. V-Wave Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37f34c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Model weights/XGBoost for P-Wave Velocity/best_xgb_model.joblib'\n",
    "best_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8745750b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df2_vp.drop(['VP', 'RHOZ', 'VOIGT_VP', 'REUSS_VP', 'VRH_VP', 'DEPT', \n",
    "                          'Voigt_Shear', 'Voigt_Bulk', 'Reuss_Shear', 'Reuss_Bulk', \n",
    "                          'K_VRH', 'G_VRH'], axis=1)\n",
    "y_test = test_df2_vp['VP']\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3f55eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2159dbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREDICTIONS\n",
    "y_test_pred_vp = best_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9daaa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(y_test, y_test_pred_vp, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "plt.title('Test Set - True vs Predicted')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c844900",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results('P-Wave Velocity [m/s]', test_df2_vp, y_test_pred_vp, y_test, 'VOIGT_VP', 'REUSS_VP','VRH_VP', 0, 7000, 2190, 1615)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff57eb3",
   "metadata": {},
   "source": [
    "### 2. S-Wave Velocity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f94c529",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'Model weights/XGBoost for S-Wave Velocity/best1_xgb_model.joblib'\n",
    "best_model = joblib.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215e0460",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df2_vs.drop(['VS', 'RHOZ', 'VOIGT_VS', 'REUSS_VS', 'VRH_VS', 'DEPT', \n",
    "                          'Voigt_Shear', 'Voigt_Bulk', 'Reuss_Shear', 'Reuss_Bulk', \n",
    "                          'K_VRH', 'G_VRH'], axis=1)\n",
    "y_test = test_df2_vs['VS']\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6893725",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_vs = best_model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b440df0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 7))\n",
    "plt.scatter(y_test, y_test_pred_vs, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4)\n",
    "plt.title('Test Set - True vs Predicted')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93c4abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results('S-Wave Velocity [m/s]', test_df2_vs, y_test_pred_vs, y_test, 'VOIGT_VS', 'REUSS_VS','VRH_VS', 0, 7000, 2190, 1615)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb17ae3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    'DEPT': test_df2_vp['DEPT'],\n",
    "    'y_test_pred_vs': y_test_pred_vs,\n",
    "    'y_test_pred_vp': y_test_pred_vp,\n",
    "    'RHOZ': test_df2_vp['RHOZ'],\n",
    "    'Voigt_Bulk': test_df2_vp['Voigt_Bulk'],\n",
    "    'Reuss_Bulk': test_df2_vp['Reuss_Bulk'],\n",
    "    'Voigt_Shear': test_df2_vp['Voigt_Shear'],\n",
    "    'Reuss_Shear': test_df2_vp['Reuss_Shear'],\n",
    "    'K_VRH': test_df2_vp['K_VRH'],\n",
    "    'G_VRH': test_df2_vp['G_VRH'],\n",
    "    'VP': test_df2_vp['VP'],\n",
    "    'VS': test_df2_vs['VS'],\n",
    "}\n",
    "\n",
    "df_kg = pd.DataFrame(data)\n",
    "\n",
    "df_kg['G_pred'] = ((df_kg['RHOZ']*1000) * df_kg['y_test_pred_vs']**2)/ 1e9\n",
    "df_kg['K_pred'] = ((df_kg['RHOZ']*1000) * (df_kg['y_test_pred_vp']**2 - (4/3) * df_kg['y_test_pred_vs']**2))/ 1e9\n",
    "\n",
    "df_kg['G'] = ((df_kg['RHOZ']*1000) * df_kg['VS']**2)/ 1e9\n",
    "df_kg['K'] = ((df_kg['RHOZ']*1000) * (df_kg['VP']**2 - (4/3) * df_kg['VS']**2))/ 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9a30f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results('Bulk Modulus [GPa]', df_kg, df_kg['K_pred'], df_kg['K'], 'Voigt_Bulk', 'Reuss_Bulk','K_VRH', 0, 100, 2190, 1615, 'yellow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e585c7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results('Shear Modulus [GPa]', df_kg, df_kg['G_pred'], df_kg['G'], 'Voigt_Shear', 'Reuss_Shear','G_VRH', 0, 60, 2190, 1615, 'yellow')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
